# ğŸ¤– Legal LoRA Fine-Tuning with TinyLlama

Fine-tuning [TinyLlama 1.1B Chat](https://huggingface.co/TinyLlama/TinyLlama-1.1B-Chat-v1.0) using LoRA (Low-Rank Adaptation) for **Legal Question Answering** in a QA format.

---

## ğŸ“Œ Project Highlights

- ğŸ§  **Model**: TinyLlama-1.1B-Chat
- âš™ï¸ **Tuning Method**: Parameter-efficient LoRA with PEFT
- ğŸ“„ **Dataset**: Custom legal QA pairs (JSONL format)
- ğŸ§ª **Inference**: Legal-style answers based on formatted prompts
- ğŸ§± **Modular**: Clean architecture with `model`, `lora`, `utils`, `inference`

---

## ğŸ—‚ï¸ Directory Overview
legal-lora-finetune/
â”œâ”€â”€ model/ # Loads base model (TinyLlama)
â”œâ”€â”€ lora/ # LoRA configuration + training
â”œâ”€â”€ utils/ # Tokenization + dataset prep
â”œâ”€â”€ inference/ # Inference pipeline
â”œâ”€â”€ output/ # Trained adapter checkpoints
â”œâ”€â”€ qa_cleaned_strict.jsonl # Cleaned QA dataset
â”œâ”€â”€ run.py # Main training script
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt


---


